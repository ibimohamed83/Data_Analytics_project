{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7aeb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca252809",
   "metadata": {},
   "source": [
    "Below code is used to clean the data. Below steps are done\n",
    "1. Read the CSV file from guthub and describe it\n",
    "2. Identify the timestamp column, convert to datetime index, verify 10-minute interval\n",
    "3. Remove any exact duplicate rows\n",
    "4. Handle missing values and if found take a mean of it\n",
    "5. Check for gaps any missing timestamps\n",
    "6. Fill Categorical value with NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae74daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV URL from gihub\n",
    "RAW_URL = \"https://raw.githubusercontent.com/ibimohamed83/Data_Analytics_project/refs/heads/main/dataset/energydata_complete.csv\"\n",
    "# Defining column name\n",
    "DATE_COL = \"date\"\n",
    "EXPECTED_FREQ = \"10min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362e10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (rows, cols): (19735, 29)\n",
      "\n",
      "Columns:\n",
      " ['date', 'Appliances', 'lights', 'T1', 'RH_1', 'T2', 'RH_2', 'T3', 'RH_3', 'T4', 'RH_4', 'T5', 'RH_5', 'T6', 'RH_6', 'T7', 'RH_7', 'T8', 'RH_8', 'T9', 'RH_9', 'T_out', 'Press_mm_hg', 'RH_out', 'Windspeed', 'Visibility', 'Tdewpoint', 'rv1', 'rv2']\n",
      "\n",
      "Dtypes:\n",
      " date               str\n",
      "Appliances       int64\n",
      "lights           int64\n",
      "T1             float64\n",
      "RH_1           float64\n",
      "T2             float64\n",
      "RH_2           float64\n",
      "T3             float64\n",
      "RH_3           float64\n",
      "T4             float64\n",
      "RH_4           float64\n",
      "T5             float64\n",
      "RH_5           float64\n",
      "T6             float64\n",
      "RH_6           float64\n",
      "T7             float64\n",
      "RH_7           float64\n",
      "T8             float64\n",
      "RH_8           float64\n",
      "T9             float64\n",
      "RH_9           float64\n",
      "T_out          float64\n",
      "Press_mm_hg    float64\n",
      "RH_out         float64\n",
      "Windspeed      float64\n",
      "Visibility     float64\n",
      "Tdewpoint      float64\n",
      "rv1            float64\n",
      "rv2            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read CSV + describe\n",
    "df = pd.read_csv(RAW_URL)\n",
    "# Describing the features in the csv file\n",
    "print(\"Shape (rows, cols):\", df.shape)\n",
    "print(\"\\nColumns:\\n\", df.columns.tolist())\n",
    "print(\"\\nDtypes:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b229305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad/unparseable dates: 0\n",
      "\n",
      "Time range: 2016-01-11 17:00:00 -> 2016-05-27 18:00:00\n",
      "% intervals equal to 10min: 100.0\n",
      "Most common time gaps:\n",
      " date\n",
      "0 days 00:10:00    19734\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify timestamp, parse, set index\n",
    "if DATE_COL not in df.columns:\n",
    "    raise ValueError(f\"Expected '{DATE_COL}' column not found.\")\n",
    "\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\")\n",
    "bad_dates = int(df[DATE_COL].isna().sum())\n",
    "print(\"\\nBad/unparseable dates:\", bad_dates)\n",
    "\n",
    "# Drop rows with invalid timestamps (if any)\n",
    "df = df.dropna(subset=[DATE_COL])\n",
    "\n",
    "# Sort by time and set as index\n",
    "df = df.sort_values(DATE_COL).set_index(DATE_COL)\n",
    "\n",
    "# Verify 10-minute interval consistency\n",
    "diffs = df.index.to_series().diff().dropna()\n",
    "expected_delta = pd.Timedelta(EXPECTED_FREQ)\n",
    "pct_expected = (diffs == expected_delta).mean() * 100\n",
    "\n",
    "print(\"\\nTime range:\", df.index.min(), \"->\", df.index.max())\n",
    "print(f\"% intervals equal to {EXPECTED_FREQ}:\", round(pct_expected, 2))\n",
    "print(\"Most common time gaps:\\n\", diffs.value_counts().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57a16acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate rows found: 0\n",
      "Duplicate timestamps found: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates (rows and timestamps)\n",
    "dup_rows = int(df.duplicated().sum())\n",
    "dup_timestamps = int(df.index.duplicated().sum())\n",
    "\n",
    "print(\"\\nDuplicate rows found:\", dup_rows)\n",
    "print(\"Duplicate timestamps found:\", dup_timestamps)\n",
    "\n",
    "if dup_rows > 0:\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "if dup_timestamps > 0:\n",
    "    df = df[~df.index.duplicated(keep=\"first\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec97ee01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing before fill: 0\n"
     ]
    }
   ],
   "source": [
    "# Missing value handling:\n",
    "# - Numeric -> mean\n",
    "# - Categorical -> mode (most frequent)\n",
    "missing_before = df.isna().sum().sum()\n",
    "print(\"\\nMissing before fill:\", int(missing_before))\n",
    "\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Fill numeric NaNs with mean\n",
    "for c in num_cols:\n",
    "    if df[c].isna().any():\n",
    "        df[c] = df[c].fillna(df[c].mean())\n",
    "\n",
    "# Fill categorical NaNs with mode\n",
    "for c in cat_cols:\n",
    "    if df[c].isna().any():\n",
    "        df[c] = df[c].fillna(df[c].mode(dropna=True).iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "745a747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing timestamps (gaps): 0\n",
      "\n",
      "Missing after fill: 0\n",
      "\n",
      "Cleaning complete. Dataset is time-indexed and contains no missing values.\n"
     ]
    }
   ],
   "source": [
    "# Gap check (missing timestamps)\n",
    "# If gaps exist, document and decide interpolation vs removal\n",
    "full_index = pd.date_range(df.index.min(), df.index.max(), freq=EXPECTED_FREQ)\n",
    "missing_timestamps = full_index.difference(df.index)\n",
    "\n",
    "print(\"\\nMissing timestamps (gaps):\", len(missing_timestamps))\n",
    "\n",
    "# 6) Final check: confirm no NaNs remain\n",
    "missing_after = int(df.isna().sum().sum())\n",
    "print(\"\\nMissing after fill:\", missing_after)\n",
    "\n",
    "assert missing_after == 0, \"There are still missing values after cleaning!\"\n",
    "\n",
    "print(\"\\nCleaning complete. Dataset is time-indexed and contains no missing values.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
